# Mini_readability_app
Загрузчик полезной информации с веб-страницы. По входной url ссылке на статью выгружает и обрабатывает с веб-страницы
поля, указанные в настройках.

Руководство запуска:
Ключи:
-h - help.
-url - указание url адреса ресурса, откуда необходимо загрузить текст.
-w - указание ограничивающей ширины текса.
-s - Название файла настроек выгрузки. (с расширением)

Настройка выгрузки:
Настройки выгрузки располагаются в папке Settings и представляют собой текстовые файлы с указанием следующих пар
ключ-значение:
1) text_width - ограничивающая ширина текста (целое число через =)
2) searching_tags - тэги, которые необходимо выгрузить с веб-страницы. 
   Указываются через = через запятую. Например, searching_tags=p,h,title,span.
   Приоритет у ключа -w больше, чем у записи параметра ширины в файле настроек.

Для запуска программы необходимо в командной строке написать следующее:
python main.py -url url_address и опционально указать ключи -w и -s.
Если параметры -w и -s не указывать, будут использоваться значения по-умолчанию: ширина текста=80, тэги=p,title,h.

Результат работы программы - созданный текстовый файл, который автоматически помещается в папку согласно url-шаблону:
http://lenta.ru/news/2013/03/dtp/index.html => [Texts]/lenta.ru/news/2013/03/dtp/index.txt

Описание структуры проекта:
1) Папка App содержит основную логику приложения.
   WebPagesHandler.py отвечает за логику получения информации с веб-страниц.
   HTMLTextParser.py отвечает за обработку html-информации.
   TextWriter.py отвечает за запись обработанной информации на устройство.
   TextGenerator.py является фасадом дял функционала генерации текста.
2) Папка Settings содержит файлы настроек генератора текста.
3) Папка Tests содержит тесты для функционала генерации текста.
4) Папка Texts содержит результаты генерации текста.
5) main.py - точка входа в приложения.

Описание алгоритма (поэтапно):
1) Загрузка и установка настроек парсинга текста.
2) Загрузка html-страницы и вытаскивание из нее тегов в соответствии с настройками ()
3) Обработка выгруженных тэгов:
   3.1) Отбивка текстовых строк пустой строкой;
   3.2) Замена вида ссылок в соответствии с установленным форматом;
   3.3) Удаление тегов из строк и unescape html символов;
   3.4) Корректировка текста по ширине;
4) Запись итогового текста в файл.

Направления улучшения/развития программы:
1) Замена переноса строк по словам на перенос с разбиением слова с целью полноценного выравнивания по ширине строки.
2) Добавление различных настроек для загрузки разнообразной полезной информации с веб-страницы. Как, например,
выгрузка ссылок на картинки, которая задается файлом настроек images_set.txt.
3) При необходимости можно добавить парсер XML (например) файлов. Тогда имеет смысл сделать абстрактный класс парсера с
переопределяемыми методами generate_readability_text и т.д.
4) Добавление обработки div блоков html.
Например, весь текст https://www.researchgate.net/blog/post/springer-nature-and-researchgate-to-move-forward-with-long-
term-content-sharing-partnership содержится в div блоках.
5) Добавление настроек для изменения вида ссылок, например.
   
Тестируемые URL:
1) https://www.codementor.io/@sheena/how-to-write-python-custom-exceptions-du107ufv9
2) https://www.programiz.com/python-programming/user-defined-exception
3) https://www.gazeta.ru/politics/2021/11/10_a_14189233.shtml
4) https://www.vesti.ru/article/2638020 
5) https://www.gazeta.ru/politics/news/2021/11/11/n_16838245.shtml
6) https://www.gazeta.ru/social/2021/11/10/14190157.shtml
7) https://www.gazeta.ru/social/news/2021/11/11/n_16838527.shtml
8) https://lenta.ru/news/2021/11/11/vzdutie/

P.S. Результаты обработки верхних ссылок уже находятся в папке Texts.

P.S. 2 варианта парсина html: без Beautiful Soup (grap_needed_html_data) и с ним (grap_needed_html_data_beautifulsoup).
Без ~ появился в силу ограничения в тз: "Не должно использоваться сторонних библиотек, впрямую решающих задачу.",
но после было получено разъяснение, что можно пользоваться.